{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:35:01.404414Z",
     "start_time": "2019-10-09T01:35:00.789368Z"
    }
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:35:01.433621Z",
     "start_time": "2019-10-09T01:35:01.408253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8.7\n"
     ]
    }
   ],
   "source": [
    "import kaggler\n",
    "print(kaggler.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:35:05.736964Z",
     "start_time": "2019-10-09T01:35:01.436242Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import gc\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from kaggler.metrics import auc\n",
    "from kaggler.model import AutoLGB\n",
    "from kaggler.preprocessing import EmbeddingEncoder, LabelEncoder, TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:35:05.822639Z",
     "start_time": "2019-10-09T01:35:05.739014Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "matplotlib.rcParams['figure.figsize'] = (8, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:35:08.079690Z",
     "start_time": "2019-10-09T01:35:05.824584Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '../input'\n",
    "\n",
    "trn = pd.read_csv(os.path.join(data_dir, \"train.csv\"))\n",
    "tst = pd.read_csv(os.path.join(data_dir, \"test.csv\"))\n",
    "sample = pd.read_csv(os.path.join(data_dir, \"sample_submission.csv\"))\n",
    "\n",
    "y_trn = trn['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:35:08.485973Z",
     "start_time": "2019-10-09T01:35:08.081991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      id: 300000\n",
      "   bin_0:      2\n",
      "   bin_1:      2\n",
      "   bin_2:      2\n",
      "   bin_3:      2\n",
      "   bin_4:      2\n",
      "   nom_0:      3\n",
      "   nom_1:      6\n",
      "   nom_2:      6\n",
      "   nom_3:      6\n",
      "   nom_4:      4\n",
      "   nom_5:    222\n",
      "   nom_6:    522\n",
      "   nom_7:   1220\n",
      "   nom_8:   2215\n",
      "   nom_9:  11981\n",
      "   ord_0:      3\n",
      "   ord_1:      5\n",
      "   ord_2:      6\n",
      "   ord_3:     15\n",
      "   ord_4:     26\n",
      "   ord_5:    192\n",
      "     day:      7\n",
      "   month:     12\n",
      "  target:      2\n"
     ]
    }
   ],
   "source": [
    "for col in trn.columns:\n",
    "    print('{:>8s}: {:6d}'.format(col, trn[col].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:35:08.568051Z",
     "start_time": "2019-10-09T01:35:08.489605Z"
    }
   },
   "outputs": [],
   "source": [
    "features = [x for x in trn.columns if x not in ['id', 'target']]\n",
    "\n",
    "features_to_emb = ['nom_5', 'nom_6', 'nom_7', 'nom_8', 'nom_9', 'ord_3', 'ord_4', 'ord_5']\n",
    "n_emb = [16, 16, 20, 20, 30, 4, 8, 16]\n",
    "\n",
    "features_not_to_emb = [x for x in features if x not in features_to_emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:35:08.643716Z",
     "start_time": "2019-10-09T01:35:08.570509Z"
    }
   },
   "outputs": [],
   "source": [
    "features_emb = []\n",
    "for n, col in zip(n_emb, features_to_emb):\n",
    "    features_emb += ['{}_{}'.format(col, i + 1) for i in range(n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:35:08.715294Z",
     "start_time": "2019-10-09T01:35:08.646100Z"
    }
   },
   "outputs": [],
   "source": [
    "n_fold = 5\n",
    "seed = 42\n",
    "cv = StratifiedKFold(n_splits=n_fold, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:35:46.863405Z",
     "start_time": "2019-10-09T01:35:08.717333Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 46) (200000, 46)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder(min_obs=50)\n",
    "te = TargetEncoder(smoothing=1, min_samples=50, cv=cv)\n",
    "\n",
    "X_trn = pd.concat([le.fit_transform(trn[features]), te.fit_transform(trn[features], y_trn)], axis=1)\n",
    "X_tst = pd.concat([le.transform(tst[features]), te.transform(tst[features])], axis=1)\n",
    "features = ['le_{}'.format(col) for col in features] + ['te_{}'.format(col) for col in features]\n",
    "\n",
    "# X_trn = le.fit_transform(trn[features])\n",
    "# X_tst = le.transform(tst[features])\n",
    "\n",
    "# X_trn = te.fit_transform(trn[features], y_trn)\n",
    "# X_tst = te.transform(tst[features])\n",
    "\n",
    "X_trn.columns = features\n",
    "X_tst.columns = features\n",
    "print(X_trn.shape, X_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:47:33.659328Z",
     "start_time": "2019-10-09T01:35:46.866630Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1008 18:35:48.713423 4486972864 deprecation.py:323] From /Users/jeong/.conda/envs/py36/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W1008 18:35:50.913494 4486972864 deprecation_wrapper.py:119] From /Users/jeong/.conda/envs/py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 191999 samples, validate on 48000 samples\n",
      "Epoch 1/100\n",
      "191999/191999 [==============================] - 4s 19us/step - loss: 0.5981 - auc: 0.6399 - val_loss: 0.5826 - val_auc: 0.7033\n",
      "Epoch 2/100\n",
      "191999/191999 [==============================] - 2s 12us/step - loss: 0.5557 - auc: 0.7124 - val_loss: 0.5566 - val_auc: 0.7133\n",
      "Epoch 3/100\n",
      "191999/191999 [==============================] - 2s 13us/step - loss: 0.5389 - auc: 0.7372 - val_loss: 0.5638 - val_auc: 0.7072\n",
      "Epoch 4/100\n",
      "191999/191999 [==============================] - 2s 13us/step - loss: 0.5269 - auc: 0.7528 - val_loss: 0.5750 - val_auc: 0.7035\n",
      "Epoch 5/100\n",
      "191999/191999 [==============================] - 2s 13us/step - loss: 0.5156 - auc: 0.7657 - val_loss: 0.5828 - val_auc: 0.6974\n",
      "Epoch 6/100\n",
      "191999/191999 [==============================] - 2s 12us/step - loss: 0.4902 - auc: 0.7949 - val_loss: 0.6070 - val_auc: 0.6836\n",
      "Epoch 7/100\n",
      "191999/191999 [==============================] - 3s 13us/step - loss: 0.4771 - auc: 0.8088 - val_loss: 0.6224 - val_auc: 0.6787\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00007: early stopping\n",
      "Feature selection and parameter tuning with CV #1\n",
      "100%|██████████| 10/10 [00:38<00:00,  3.88s/it, best loss: -0.8114332381570969]\n",
      "100%|██████████| 100/100 [07:23<00:00,  3.83s/it, best loss: -0.8213996078011989]\n",
      "AUC (CV #1): 0.7818\n",
      "Train on 192000 samples, validate on 48000 samples\n",
      "Epoch 1/100\n",
      "192000/192000 [==============================] - 4s 19us/step - loss: 0.5953 - auc: 0.6418 - val_loss: 0.5748 - val_auc: 0.7037\n",
      "Epoch 2/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.5540 - auc: 0.7145 - val_loss: 0.5585 - val_auc: 0.7102\n",
      "Epoch 3/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.5372 - auc: 0.7389 - val_loss: 0.5707 - val_auc: 0.7049\n",
      "Epoch 4/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.5256 - auc: 0.7536 - val_loss: 0.5768 - val_auc: 0.7008\n",
      "Epoch 5/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.5130 - auc: 0.7688 - val_loss: 0.5892 - val_auc: 0.6961\n",
      "Epoch 6/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.4854 - auc: 0.7998 - val_loss: 0.6120 - val_auc: 0.6810\n",
      "Epoch 7/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.4726 - auc: 0.8135 - val_loss: 0.6325 - val_auc: 0.6780\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00007: early stopping\n",
      "AUC (CV #2): 0.7775\n",
      "Train on 192000 samples, validate on 48000 samples\n",
      "Epoch 1/100\n",
      "192000/192000 [==============================] - 4s 20us/step - loss: 0.5989 - auc: 0.6357 - val_loss: 0.5815 - val_auc: 0.7038\n",
      "Epoch 2/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.5559 - auc: 0.7118 - val_loss: 0.5586 - val_auc: 0.7097\n",
      "Epoch 3/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.5402 - auc: 0.7349 - val_loss: 0.5607 - val_auc: 0.7057\n",
      "Epoch 4/100\n",
      "192000/192000 [==============================] - 2s 13us/step - loss: 0.5278 - auc: 0.7508 - val_loss: 0.5690 - val_auc: 0.7008\n",
      "Epoch 5/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.5171 - auc: 0.7630 - val_loss: 0.5892 - val_auc: 0.6940\n",
      "Epoch 6/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.4913 - auc: 0.7931 - val_loss: 0.6046 - val_auc: 0.6845\n",
      "Epoch 7/100\n",
      "192000/192000 [==============================] - 2s 12us/step - loss: 0.4800 - auc: 0.8055 - val_loss: 0.6265 - val_auc: 0.6793\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00007: early stopping\n",
      "AUC (CV #3): 0.7850\n",
      "Train on 192000 samples, validate on 48000 samples\n",
      "Epoch 1/100\n",
      "192000/192000 [==============================] - 4s 21us/step - loss: 0.5925 - auc: 0.6484 - val_loss: 0.5813 - val_auc: 0.7054\n",
      "Epoch 2/100\n",
      "192000/192000 [==============================] - 3s 14us/step - loss: 0.5552 - auc: 0.7128 - val_loss: 0.5579 - val_auc: 0.7105\n",
      "Epoch 3/100\n",
      "192000/192000 [==============================] - 3s 14us/step - loss: 0.5395 - auc: 0.7368 - val_loss: 0.5600 - val_auc: 0.7069\n",
      "Epoch 4/100\n",
      "192000/192000 [==============================] - 3s 14us/step - loss: 0.5272 - auc: 0.7524 - val_loss: 0.5701 - val_auc: 0.7001\n",
      "Epoch 5/100\n",
      "192000/192000 [==============================] - 3s 14us/step - loss: 0.5151 - auc: 0.7672 - val_loss: 0.5852 - val_auc: 0.6954\n",
      "Epoch 6/100\n",
      "192000/192000 [==============================] - 3s 14us/step - loss: 0.4878 - auc: 0.7991 - val_loss: 0.6088 - val_auc: 0.6785\n",
      "Epoch 7/100\n",
      "192000/192000 [==============================] - 3s 14us/step - loss: 0.4730 - auc: 0.8136 - val_loss: 0.6322 - val_auc: 0.6774\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00007: early stopping\n",
      "AUC (CV #4): 0.7804\n",
      "Train on 192000 samples, validate on 48001 samples\n",
      "Epoch 1/100\n",
      "192000/192000 [==============================] - 4s 22us/step - loss: 0.5943 - auc: 0.6443 - val_loss: 0.5846 - val_auc: 0.7000\n",
      "Epoch 2/100\n",
      "192000/192000 [==============================] - 3s 14us/step - loss: 0.5555 - auc: 0.7127 - val_loss: 0.5599 - val_auc: 0.7034\n",
      "Epoch 3/100\n",
      "192000/192000 [==============================] - 3s 13us/step - loss: 0.5400 - auc: 0.7364 - val_loss: 0.5692 - val_auc: 0.6982\n",
      "Epoch 4/100\n",
      "192000/192000 [==============================] - 3s 14us/step - loss: 0.5263 - auc: 0.7525 - val_loss: 0.5775 - val_auc: 0.6937\n",
      "Epoch 5/100\n",
      "192000/192000 [==============================] - 3s 13us/step - loss: 0.5160 - auc: 0.7656 - val_loss: 0.5837 - val_auc: 0.6898\n",
      "Epoch 6/100\n",
      "192000/192000 [==============================] - 3s 14us/step - loss: 0.4910 - auc: 0.7945 - val_loss: 0.6031 - val_auc: 0.6750\n",
      "Epoch 7/100\n",
      "192000/192000 [==============================] - 3s 14us/step - loss: 0.4788 - auc: 0.8066 - val_loss: 0.6358 - val_auc: 0.6745\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00007: early stopping\n",
      "AUC (CV #5): 0.7152\n",
      "AUC CV: 0.7681\n"
     ]
    }
   ],
   "source": [
    "p = np.zeros((trn.shape[0],))\n",
    "p_tst = np.zeros((tst.shape[0],))\n",
    "\n",
    "features += features_emb\n",
    "for i, (i_trn, i_val) in enumerate(cv.split(X_trn, y_trn), 1):\n",
    "    y_trn_cv = y_trn[i_trn].reset_index(drop=True)\n",
    "\n",
    "    ee = EmbeddingEncoder(cat_cols=features_to_emb, num_cols=[], n_emb=n_emb, random_state=seed)\n",
    "    X_emb_trn = ee.fit_transform(trn.loc[i_trn, features_to_emb], y_trn_cv)\n",
    "    X_emb_val = ee.transform(trn.loc[i_val, features_to_emb])\n",
    "    X_emb_tst = ee.transform(tst[features_to_emb])\n",
    "    \n",
    "    X_trn_cv = pd.concat([X_trn.loc[i_trn].reset_index(drop=True), \n",
    "                          pd.DataFrame(X_emb_trn, columns=features_emb)], axis=1)\n",
    "    X_val_cv = pd.concat([X_trn.loc[i_val].reset_index(drop=True), \n",
    "                          pd.DataFrame(X_emb_val, columns=features_emb)], axis=1)\n",
    "    X_tst_cv = pd.concat([X_tst, pd.DataFrame(X_emb_tst, columns=features_emb)], axis=1)\n",
    "\n",
    "#     X_trn_cv = X_trn.loc[i_trn].reset_index(drop=True)\n",
    "#     X_val_cv = X_trn.loc[i_val].reset_index(drop=True)\n",
    "   \n",
    "    if i == 1:\n",
    "        print('Feature selection and parameter tuning with CV #{}'.format(i))\n",
    "        model = AutoLGB(objective='binary', metric='auc', sample_size=50000, random_state=seed)\n",
    "        model.tune(X_trn_cv, y_trn_cv)\n",
    "        \n",
    "    model.fit(X_trn_cv, y_trn_cv)\n",
    "    p[i_val] = model.predict(X_val_cv)\n",
    "    print('AUC (CV #{}): {:.4f}'.format(i, auc(y_trn[i_val], p[i_val])))\n",
    "    p_tst += model.predict(X_tst_cv) / n_fold\n",
    "    \n",
    "print('AUC CV: {:.4f}'.format(auc(y_trn, p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:47:33.736570Z",
     "start_time": "2019-10-09T01:47:33.661322Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138 features selected out of 176\n"
     ]
    }
   ],
   "source": [
    "print('{} features selected out of {}'.format(len(model.features), len(features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-09T01:47:34.599027Z",
     "start_time": "2019-10-09T01:47:33.738760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving submission file\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving submission file\")\n",
    "submission = pd.DataFrame.from_dict({\n",
    "    'id': tst.id.values,\n",
    "    'target': p_tst\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
